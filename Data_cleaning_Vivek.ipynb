{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmC8O43asN1bfCoPBf+zIS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekab5/Email-Scraper-Pro/blob/master/Data_cleaning_Vivek.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D22EDsKWDMSX"
      },
      "outputs": [],
      "source": [
        "!pip install -q tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "from IPython.display import display\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "input_file = list(uploaded.keys())[0]\n",
        "output_file = \"cleaned_websites.csv\"\n",
        "\n",
        "\n",
        "def load_websites(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    column = df.columns[0]\n",
        "    return list(set(df[column].dropna().str.strip().str.lower()))\n",
        "\n",
        "\n",
        "def check_website(url):\n",
        "    try:\n",
        "        if not url.startswith(('http://', 'https://')):\n",
        "            url = 'http://' + url\n",
        "        response = requests.get(url, timeout=10)\n",
        "        if response.status_code < 400:\n",
        "            return url, \"Working\"\n",
        "        else:\n",
        "            return url, f\"Issue (Status: {response.status_code})\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return url, f\"Error ({str(e)})\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    websites = load_websites(input_file)\n",
        "    print(f\"Checking {len(websites)} websites...\\n\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=50) as executor:\n",
        "        results = list(tqdm(executor.map(check_website, websites), total=len(websites)))\n",
        "\n",
        "\n",
        "    df_output = pd.DataFrame(results, columns=[\"Website\", \"Status\"])\n",
        "    df_output.to_csv(output_file, index=False)\n",
        "    print(f\"\\nCompleted. Results saved to '{output_file}'\")\n",
        "\n",
        "\n",
        "    files.download(output_file)\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "id": "EvloGiO-DsHB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}